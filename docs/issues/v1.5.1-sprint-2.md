# v1.5.1 Sprint 2: Example Output Validation with CDL Comparison

**Labels:** enhancement, v1.5.1, sprint-2

**Depends on:** Sprint 1 (examples must be integrated and running)

## Overview
Add automated validation of example program output by comparing generated NetCDF files against expected CDL (Common Data Language) baselines. This provides regression testing to ensure examples continue producing correct output.

## Tasks

### CDL Reference Files
- [ ] Run each example program to generate NetCDF output files
- [ ] Use `ncdump` to create CDL representation of each output file
- [ ] Store CDL files in `examples/expected_output/` directory
- [ ] Use naming convention: `<example_name>_expected.cdl` (e.g., `simple_2D_expected.cdl`)
- [ ] Add CDL files to repository as regression test baselines

### Test Enhancement
- [ ] Modify test scripts to capture example program output
- [ ] Run `ncdump` on generated NetCDF files after each example executes
- [ ] Compare ncdump output against stored CDL files using text comparison
- [ ] Test fails if output differs from expected CDL (indicates regression)
- [ ] Provide clear error messages showing differences when validation fails

### CMake Test Updates
- [ ] Add custom test commands that run example + ncdump + comparison
- [ ] Use CMake's `add_test()` with comparison logic
- [ ] Store generated files in build directory for inspection
- [ ] Clean up temporary files after successful tests
- [ ] Ensure tests work with both in-tree and out-of-tree builds

### Autotools Test Updates
- [ ] Create shell scripts for each example that perform: execute → ncdump → compare
- [ ] Add scripts to TESTS variable in Makefile.am
- [ ] Use `diff` or similar tool for CDL comparison
- [ ] Report failures with helpful diagnostics
- [ ] Handle both in-tree and VPATH builds correctly

### Documentation Updates
- [ ] Update `examples/README.md` with explanation of CDL validation
- [ ] Document how to regenerate expected CDL files if intentional changes occur
- [ ] Add troubleshooting section for common validation failures
- [ ] Explain purpose of regression testing for examples
- [ ] Document CDL file format and location

### CI Integration
- [ ] Verify examples run with CDL validation in CI pipeline
- [ ] CDL validation catches regressions automatically
- [ ] No additional CI workflow changes needed (examples use existing test infrastructure)
- [ ] Ensure CI fails if example output changes unexpectedly

## Expected Output Structure
```
examples/
├── expected_output/
│   ├── simple_2D_expected.cdl
│   ├── coord_vars_expected.cdl
│   ├── format_variants_expected.cdl
│   ├── size_limits_expected.cdl
│   ├── unlimited_dim_expected.cdl
│   ├── var4d_expected.cdl
│   ├── simple_nc4_expected.cdl
│   ├── compression_expected.cdl
│   ├── chunking_performance_expected.cdl
│   ├── multi_unlimited_expected.cdl
│   ├── user_types_expected.cdl
│   ├── f_simple_2D_expected.cdl
│   ├── f_coord_vars_expected.cdl
│   ├── f_format_variants_expected.cdl
│   ├── f_size_limits_expected.cdl
│   ├── f_unlimited_dim_expected.cdl
│   ├── f_var4d_expected.cdl
│   ├── f_simple_nc4_expected.cdl
│   ├── f_compression_expected.cdl
│   ├── f_chunking_performance_expected.cdl
│   ├── f_multi_unlimited_expected.cdl
│   └── f_user_types_expected.cdl
└── README.md (updated with validation documentation)
```

## Definition of Done
- [ ] All example programs have corresponding expected CDL files
- [ ] CMake tests validate example output against CDL baselines
- [ ] Autotools tests validate example output against CDL baselines
- [ ] Tests fail appropriately when output differs from expected
- [ ] Documentation explains validation approach and how to update baselines
- [ ] CI pipeline validates all examples automatically
- [ ] Both C and Fortran examples have CDL validation
